{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mount drive to colab**"
      ],
      "metadata": {
        "id": "ZfkxSlXRYRKV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyEANpr5Esdy",
        "outputId": "b37ecfd0-23e3-48a1-c2f9-445377114709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unzipping the dataset**"
      ],
      "metadata": {
        "id": "xQncGMXUYaKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V2anqLaQZXjf"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBJECT DETECTION**\n"
      ],
      "metadata": {
        "id": "GIr3R16hVzxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import necessary libraries**"
      ],
      "metadata": {
        "id": "IIHqUCf5YrdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TmgO_Vy0qzcW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main function**"
      ],
      "metadata": {
        "id": "y1_Ef6_WXe5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    model = get_model()\n",
        "    dataset_dir = '/content/dataset'\n",
        "    process_dataset(dataset_dir, model, get_transform())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "67VjaE61XdGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the pre-existing model**"
      ],
      "metadata": {
        "id": "JlYd6NjDWLpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faster R-CNN model\n",
        "def get_model():\n",
        "\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "g1J8Z1MBWKEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation(converting images to tensors)**"
      ],
      "metadata": {
        "id": "R3zFOcQLWhOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to transform input image\n",
        "def get_transform():\n",
        "    transform = T.Compose([\n",
        "        T.ToTensor(),  # Convert PIL image or numpy array to a tensor\n",
        "    ])\n",
        "    return transform"
      ],
      "metadata": {
        "id": "28NfXDXsWgSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing inference**"
      ],
      "metadata": {
        "id": "h6beaB3jW77x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform inference on a single image\n",
        "def detect_objects(image_path, model, transform):\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Apply the transformation to the image\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Perform the inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "4tmC2cwvWs6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**visualizing**"
      ],
      "metadata": {
        "id": "ta2RA45SXJ7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(image_path, outputs, threshold=0.5):\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Get the bounding boxes and labels\n",
        "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
        "    scores = outputs[0]['scores'].cpu().numpy()\n",
        "\n",
        "    # Draw the boxes on the image\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > threshold:\n",
        "            # Convert box coordinates to integers\n",
        "            box = box.astype(int)\n",
        "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), color=(0, 255, 0), thickness=2)\n",
        "\n",
        "    # Save the image with detections\n",
        "    result_image_path = os.path.join('results', os.path.basename(image_path))\n",
        "    cv2.imwrite(result_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "id": "lcD6TlQtXH2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to process a directory of images and saving the result in results directory**"
      ],
      "metadata": {
        "id": "knYwo8Y-Xqlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(dataset_dir, model, transform):\n",
        "    # Create a results directory if it doesn't exist\n",
        "    if not os.path.exists('results'):\n",
        "        os.makedirs('results')\n",
        "\n",
        "    # Iterate over all images in the directory\n",
        "    for image_name in os.listdir(dataset_dir):\n",
        "        image_path = os.path.join(dataset_dir, image_name)\n",
        "\n",
        "        if image_path.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing {image_name}...\")\n",
        "            outputs = detect_objects(image_path, model, transform)\n",
        "            visualize_results(image_path, outputs)"
      ],
      "metadata": {
        "id": "hwD7r2rPXmbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANALYZING THE FRQUENCY OF OBJECTS DETECTED**"
      ],
      "metadata": {
        "id": "8oesULXcY9SU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import necessary libraries**"
      ],
      "metadata": {
        "id": "aoebta2YZPxM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3EkIpsrtq35N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main function**"
      ],
      "metadata": {
        "id": "ft7_2lJfa9oY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    model = get_model()\n",
        "    dataset_dir = '/content/dataset'\n",
        "    object_catalog = process_dataset(dataset_dir, model, get_transform())\n",
        "\n",
        "    total_objects = sum(object_catalog.values())\n",
        "    print(f\"Total objects detected: {total_objects}\")\n",
        "    for obj, count in object_catalog.items():\n",
        "        print(f\"{obj}: {count} ({(count/total_objects)*100:.2f}%)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "qahjGujpa76n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COCO class labels**"
      ],
      "metadata": {
        "id": "0GJFQaZ7ZnJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO class labels\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\n",
        "    'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
        "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
        "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A',\n",
        "    'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock',\n",
        "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n"
      ],
      "metadata": {
        "id": "DT8G8cGcZlQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model loading and image transformation for object detection**"
      ],
      "metadata": {
        "id": "awq2VawKZ-4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the pretrained Faster R-CNN model\n",
        "def get_model():\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to transform input image\n",
        "def get_transform():\n",
        "    transform = T.Compose([\n",
        "        T.ToTensor(),\n",
        "    ])\n",
        "    return transform\n",
        "# Function to perform inference on a single image\n",
        "def detect_objects(image_path, model, transform):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "hFP8Nk56Z9wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process the data and cataloging the objects**"
      ],
      "metadata": {
        "id": "zbyykr77afke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_and_catalog(image_path, outputs, object_catalog, threshold=0.5):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    boxes = outputs[0]['boxes'].cpu().numpy()\n",
        "    scores = outputs[0]['scores'].cpu().numpy()\n",
        "    labels = outputs[0]['labels'].cpu().numpy()\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > threshold:\n",
        "            # Convert box coordinates to integers\n",
        "            box = box.astype(int)\n",
        "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), color=(0, 255, 0), thickness=2)\n",
        "            label = labels[i]\n",
        "            object_catalog[COCO_INSTANCE_CATEGORY_NAMES[label]] += 1\n",
        "\n",
        "    result_image_path = os.path.join('results', os.path.basename(image_path))\n",
        "    cv2.imwrite(result_image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "id": "vYyQfGCUaNd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to process a directory of images and catalog objects**"
      ],
      "metadata": {
        "id": "jFeXd5AWa2hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(dataset_dir, model, transform):\n",
        "    if not os.path.exists('results'):\n",
        "        os.makedirs('results')\n",
        "\n",
        "    object_catalog = defaultdict(int)\n",
        "\n",
        "    for image_name in os.listdir(dataset_dir):\n",
        "        image_path = os.path.join(dataset_dir, image_name)\n",
        "        if image_path.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            print(f\"Processing {image_name}...\")\n",
        "            outputs = detect_objects(image_path, model, transform)\n",
        "            visualize_and_catalog(image_path, outputs, object_catalog)\n",
        "\n",
        "    return object_catalog"
      ],
      "metadata": {
        "id": "0Q-BJw0YazkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}